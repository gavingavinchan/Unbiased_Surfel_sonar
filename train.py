#
# Copyright (C) 2023, Inria
# GRAPHDECO research group, https://team.inria.fr/graphdeco
# All rights reserved.
#
# This software is free for non-commercial, research and evaluation use 
# under the terms of the LICENSE.md file.
#
# For inquiries contact  george.drettakis@inria.fr
#

import os
import sys
from random import randint

import json
import torch
import numpy as np
from PIL import Image
import cv2
from tqdm import tqdm
import uuid
from argparse import ArgumentParser, Namespace

from utils.loss_utils import l1_loss, ssim
from gaussian_renderer import render, render_sonar, network_gui
from scene import Scene, GaussianModel
from utils.general_utils import safe_state
from utils.image_utils import psnr, render_net_image
from utils.sonar_utils import SonarScaleFactor, SonarConfig, SonarExtrinsic, build_sonar_config
from arguments import ModelParams, PipelineParams, OptimizationParams
try:
    from torch.utils.tensorboard import SummaryWriter
    TENSORBOARD_FOUND = True
except ImportError:
    TENSORBOARD_FOUND = False

def training(dataset: ModelParams,
             opt:     OptimizationParams,
             pipe:    PipelineParams,
             testing_iterations,
             saving_iterations,
             checkpoint_iterations,
             checkpoint,
             logger_enabled):
    first_iter = 0
    tb_writer = prepare_output_and_logger(dataset, logger_enabled)
    gaussians = GaussianModel(dataset.sh_degree)
    scene = Scene(dataset, gaussians, shuffle=False)  ## load data
    gaussians.training_setup(opt)
    scene.training_setup(opt)
    if checkpoint:
        (model_params, first_iter) = torch.load(checkpoint)
        gaussians.restore(model_params, opt)

    bg_color = [1, 1, 1] if dataset.white_background else [0, 0, 0]
    background = torch.tensor(bg_color, dtype=torch.float32, device="cuda")

    # Sonar mode setup
    sonar_scale_factor = None
    sonar_config = None
    sonar_optimizer = None
    sonar_extrinsic = None
    if dataset.sonar_mode:
        print("Sonar mode enabled - initializing sonar scale factor and config")
        sonar_config = build_sonar_config(dataset)
        sonar_scale_factor = SonarScaleFactor(init_value=dataset.sonar_scale_init).cuda()
        sonar_extrinsic = SonarExtrinsic(device="cuda")
        sonar_optimizer = torch.optim.Adam(
            sonar_scale_factor.parameters(), 
            lr=dataset.sonar_scale_lr
        )
        print(f"  Initial scale factor: {sonar_scale_factor.get_scale_value():.4f}")
        # print(f"  log_scale param: {sonar_scale_factor._log_scale.item():.4f}")
        print(f"  Scale factor learning rate: {dataset.sonar_scale_lr}")
        print(f"  Camera-to-sonar extrinsic: 10cm offset, 5deg pitch down")

    iter_start = torch.cuda.Event(enable_timing = True)
    iter_end = torch.cuda.Event(enable_timing = True)

    viewpoint_stack = None
    ema_loss_for_log = 0.0
    ema_dist_for_log = 0.0
    ema_normal_for_log = 0.0
    ema_converge_for_log = 0.0

    progress_bar = tqdm(range(first_iter, opt.iterations), desc="Training progress")
    first_iter += 1
    for iteration in range(first_iter, opt.iterations + 1):        

        iter_start.record()

        gaussians.update_learning_rate(iteration)

        # Every 1000 its we increase the levels of SH up to a maximum degree
        if iteration % 1000 == 0:
            gaussians.oneupSHdegree()

        # Pick a random Camera
        if not viewpoint_stack:
            viewpoint_stack = scene.getTrainCameras().copy()
        viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1))
        
        # Render scene (different path for sonar vs camera)
        if dataset.sonar_mode and sonar_config is not None:
            render_pkg = render_sonar(
                viewpoint_cam, gaussians, background,
                sonar_config=sonar_config,
                scale_factor=sonar_scale_factor,
                sonar_extrinsic=sonar_extrinsic
            )
        else:
            render_pkg = render(viewpoint_cam, gaussians, pipe, background)
        
        image                  = render_pkg["render"]
        viewspace_point_tensor = render_pkg["viewspace_points"]
        visibility_filter      = render_pkg["visibility_filter"]
        radii                  = render_pkg["radii"]
        converge               = render_pkg["converge"]

        # Gamma corrected Image (only for camera mode)
        gt_image = viewpoint_cam.original_image.cuda()
        if not dataset.sonar_mode:
            gt_image = gt_image.pow(dataset.gamma)
        else:
            # Mask out top rows for sonar (closest range bins often have artifacts)
            # TODO: Make this configurable via dataset.sonar_mask_top_rows
            mask_top_rows = 10
            if mask_top_rows > 0:
                gt_image = gt_image.clone()  # Don't modify original
                gt_image[:, :mask_top_rows, :] = 0

        ssim_value = ssim(image, gt_image)
        Ll1 = l1_loss(image, gt_image)
        loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim_value)

        # regularization
        # Disable normal loss for sonar mode (surf_normal can have nans from empty regions)
        if dataset.sonar_mode:
            lambda_normal = 0.0
            lambda_dist = 0.0
        else:
            lambda_normal = opt.lambda_normal if iteration > 7000 else 0.0
            lambda_dist = opt.lambda_dist if iteration > 3000 else 0.0

        # Converge Loss
        lambda_converge = opt.lambda_converge if iteration > 10000 else 0.00
        converge_loss = lambda_converge * converge.mean()

        # Normal and dist losses (skip for sonar mode to avoid nan from surf_normal)
        if dataset.sonar_mode:
            # Skip normal/dist regularization for sonar - surf_normal can have nans
            normal_loss = torch.tensor(0.0, device=image.device)
            dist_loss = torch.tensor(0.0, device=image.device)
        else:
            rend_dist   = render_pkg["rend_dist"]  
            rend_normal = render_pkg['rend_normal']
            surf_normal = render_pkg['surf_normal']
            normal_error = (1 - (rend_normal * surf_normal).sum(dim=0))[None]
            normal_loss = lambda_normal * (normal_error).mean()
            dist_loss = lambda_dist * (rend_dist).mean()

        # loss
        total_loss = loss + dist_loss + normal_loss + converge_loss
        
        total_loss.backward()

        iter_end.record()

        with torch.no_grad():
            # Progress bar
            ema_loss_for_log = 0.4 * loss.item() + 0.6 * ema_loss_for_log
            # ema_dist_for_log = 0.4 * dist_loss.item() + 0.6 * ema_dist_for_log
            ema_normal_for_log = 0.4 * normal_loss.item() + 0.6 * ema_normal_for_log
            ema_converge_for_log = 0.4 * converge_loss.item() + 0.6 * ema_converge_for_log

            if iteration % 10 == 0:
                loss_dict = {
                    "Loss": f"{ema_loss_for_log:.{5}f}",
                    # "distort": f"{ema_dist_for_log:.{5}f}",
                    "normal": f"{ema_normal_for_log:.{5}f}",
                    "converge": f"{ema_converge_for_log:.{5}f}",
                    "Points": f"{len(gaussians.get_xyz)}"  
                }
                # Add scale factor to progress bar in sonar mode
                if dataset.sonar_mode and sonar_scale_factor is not None:
                    loss_dict["scale"] = f"{sonar_scale_factor.get_scale_value():.{4}f}"
                progress_bar.set_postfix(loss_dict)

                progress_bar.update(10)

            if iteration == opt.iterations:
                progress_bar.close()

            # Log and save
            if tb_writer is not None:
                tb_writer.add_scalar('train_loss_patches/dist_loss', ema_dist_for_log, iteration)
                tb_writer.add_scalar('train_loss_patches/normal_loss', ema_normal_for_log, iteration)
                
                # Sonar-specific TensorBoard logging
                if dataset.sonar_mode and sonar_scale_factor is not None:
                    # Log scale factor value (should converge to a stable number)
                    scale_val = sonar_scale_factor.get_scale_value()
                    tb_writer.add_scalar('sonar/scale_factor', scale_val, iteration)
                    
                    # Log scale factor gradient magnitude (should decrease as it converges)
                    scale_grad = sonar_scale_factor.get_log_scale_grad()
                    tb_writer.add_scalar('sonar/scale_factor_grad', abs(scale_grad), iteration)
                    
                    # Log rendered vs GT range statistics periodically
                    if iteration % 100 == 0:
                        surf_range = render_pkg.get('surf_depth')  # This is range for sonar
                        if surf_range is not None:
                            # Get valid mask from GT image
                            gt_valid = gt_image > dataset.sonar_intensity_threshold
                            if gt_valid.any():
                                # Mean rendered range for valid pixels
                                rendered_range = surf_range[gt_valid].mean().item()
                                tb_writer.add_scalar('sonar/rendered_mean_range', rendered_range, iteration)

            # Select appropriate render function for training report
            if dataset.sonar_mode and sonar_config is not None:
                # Create a wrapper that matches the expected signature for render()
                def sonar_render_wrapper(viewpoint, gaussians, pipe, bg):
                    return render_sonar(viewpoint, gaussians, bg, sonar_config, sonar_scale_factor, sonar_extrinsic)
                training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end),
                                testing_iterations, scene, sonar_render_wrapper, (pipe, background), dataset)
            else:
                training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end),
                                testing_iterations, scene, render, (pipe, background), dataset)
            if (iteration in saving_iterations):
                print("\n[ITER {}] Saving Gaussians".format(iteration))
                scene.save(iteration)

            # Densification
            # Note: In sonar mode, gradients may not flow through the Python splatting
            if iteration < opt.densify_until_iter:
                # Only update stats if we have valid radii and gradients
                if radii.any() and viewspace_point_tensor.grad is not None:
                    gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])
                    gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)

                if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:
                    size_threshold = 20 if iteration > opt.opacity_reset_interval else None
                    gaussians.densify_and_prune(opt.densify_grad_threshold, opt.opacity_cull, scene.cameras_extent, size_threshold)
                
                if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter):
                    gaussians.reset_opacity()

            # Optimizer step
            if iteration < opt.iterations:
                gaussians.optimizer.step()
                gaussians.optimizer.zero_grad(set_to_none = True)
                
                # Sonar scale factor optimizer step
                if sonar_optimizer is not None:
                    sonar_optimizer.step()
                    sonar_optimizer.zero_grad(set_to_none=True)

            # Maximum size limit
            if iteration >= opt.densify_until_iter:
                gaussians.clamp_scaling(torch.tensor(0.1 * scene.cameras_extent).cuda())

            if (iteration in checkpoint_iterations):
                print("\n[ITER {}] Saving Checkpoint".format(iteration))
                torch.save((gaussians.capture(), iteration), scene.model_path + "/chkpnt" + str(iteration) + ".pth")

        with torch.no_grad():        
            if network_gui.conn == None:
                network_gui.try_connect(dataset.render_items)
            while network_gui.conn != None:
                try:
                    net_image_bytes = None
                    custom_cam, do_training, keep_alive, scaling_modifer, render_mode = network_gui.receive()
                    if custom_cam != None:
                        render_pkg = render(custom_cam, gaussians, pipe, background, scaling_modifer)   
                        net_image = render_net_image(render_pkg, dataset.render_items, render_mode, custom_cam)
                        net_image_bytes = memoryview((torch.clamp(net_image, min=0, max=1.0) * 255).byte().permute(1, 2, 0).contiguous().cpu().numpy())
                    metrics_dict = {
                        "#": gaussians.get_opacity.shape[0],
                        "loss": ema_loss_for_log
                        # Add more metrics as needed
                    }
                    # Send the data
                    network_gui.send(net_image_bytes, dataset.source_path, metrics_dict)
                    if do_training and ((iteration < int(opt.iterations)) or not keep_alive):
                        break
                except Exception as e:
                    # raise e
                    network_gui.conn = None

def prepare_output_and_logger(args, logger_enabled):    
    if not args.model_path:
        if os.getenv('OAR_JOB_ID'):
            unique_str=os.getenv('OAR_JOB_ID')
        else:
            unique_str = str(uuid.uuid4())
        args.model_path = os.path.join("./output/", unique_str[0:10])

    # Set up output folder
    print("Output folder: {}".format(args.model_path))
    os.makedirs(args.model_path, exist_ok = True)
    with open(os.path.join(args.model_path, "cfg_args"), 'w') as cfg_log_f:
        cfg_log_f.write(str(Namespace(**vars(args))))

    # Create Tensorboard writer
    tb_writer = None
    if TENSORBOARD_FOUND and logger_enabled:
        tb_writer = SummaryWriter(args.model_path)
    else:
        print("Tensorboard not available: not logging progress")
    return tb_writer

@torch.no_grad()
def training_report(
    tb_writer, iteration,
    Ll1, loss, l1_loss,
    elapsed,
    testing_iterations,
    scene : Scene,
    renderFunc,
    renderArgs,
    dataset: ModelParams):
    if tb_writer:
        tb_writer.add_scalar('train_loss_patches/reg_loss', Ll1.item(), iteration)
        tb_writer.add_scalar('train_loss_patches/total_loss', loss.item(), iteration)
        tb_writer.add_scalar('iter_time', elapsed, iteration)
        tb_writer.add_scalar('total_points', scene.gaussians.get_xyz.shape[0], iteration)

    # Report test and samples of training set
    if iteration in testing_iterations:
        torch.cuda.empty_cache()
        validation_configs = ({'name': 'test', 'cameras' : scene.getTestCameras()}, 
                              {'name': 'train', 'cameras' : [scene.getTrainCameras()[idx % len(scene.getTrainCameras())] for idx in range(5, 30, 5)]})
        data = {'test': {}, 'train': {}}

        # Select cameras for training and testing
        for config in validation_configs:
            if config['cameras'] and len(config['cameras']) > 0:
                l1_test = 0.0
                psnr_test = 0.0
                # Traverse cameras
                for idx, viewpoint in enumerate(config['cameras']):
                    render_pkg = renderFunc(viewpoint, scene.gaussians, *renderArgs)

                    image = torch.clamp(render_pkg["render"].pow(1.0 / dataset.gamma), 0.0, 1.0)
                    gt_image = torch.clamp(viewpoint.original_image.to("cuda"), 0.0, 1.0)
                    
                    if tb_writer and (idx < 5):
                        from utils.general_utils import colormap
                        depth = render_pkg["surf_depth"]
                        norm = depth.max()
                        depth = depth / norm
                        depth = colormap(depth.cpu().numpy()[0], cmap='turbo')
                        tb_writer.add_images(config['name'] + "_view_{}/depth".format(viewpoint.image_name), depth[None], global_step=iteration)
                        tb_writer.add_images(config['name'] + "_view_{}/render".format(viewpoint.image_name), image[None], global_step=iteration)

                        try:
                            rend_alpha = render_pkg['rend_alpha']
                            rend_normal = render_pkg["rend_normal"] * 0.5 + 0.5
                            surf_normal = render_pkg["surf_normal"] * 0.5 + 0.5
                            tb_writer.add_images(config['name'] + "_view_{}/rend_normal".format(viewpoint.image_name), rend_normal[None], global_step=iteration)
                            tb_writer.add_images(config['name'] + "_view_{}/surf_normal".format(viewpoint.image_name), surf_normal[None], global_step=iteration)
                            tb_writer.add_images(config['name'] + "_view_{}/rend_alpha".format(viewpoint.image_name), rend_alpha[None], global_step=iteration)

                            rend_dist = render_pkg["rend_dist"]
                            rend_dist = colormap(rend_dist.cpu().numpy()[0])
                            tb_writer.add_images(config['name'] + "_view_{}/rend_dist".format(viewpoint.image_name), rend_dist[None], global_step=iteration)
                        except:
                            pass

                        if iteration == testing_iterations[0]:
                            tb_writer.add_images(config['name'] + "_view_{}/ground_truth".format(viewpoint.image_name), gt_image[None], global_step=iteration)

                    l1_test += l1_loss(image, gt_image).mean().double()
                    psnr_test += psnr(image, gt_image).mean().double()

                psnr_test /= len(config['cameras'])
                l1_test /= len(config['cameras'])
                print("\n[ITER {}] Evaluating {}: L1 {} PSNR {}".format(iteration, config['name'], l1_test, psnr_test))
                if tb_writer:
                    tb_writer.add_scalar(config['name'] + '/loss_viewpoint - l1_loss', l1_test, iteration)
                    tb_writer.add_scalar(config['name'] + '/loss_viewpoint - psnr', psnr_test, iteration)

                data[config['name']][f'{iteration}_psnr'] = psnr_test.item()
                data[config['name']][f'{iteration}_l1'] = l1_test.item()
        
        # Write to output.json
        with open(os.path.join(scene.model_path, "output.json"), 'w') as file:
            json.dump(data, file)

        torch.cuda.empty_cache()

if __name__ == "__main__":
    # Set up command line argument parser
    parser = ArgumentParser(description="Training script parameters")
    lp = ModelParams(parser)
    op = OptimizationParams(parser)
    pp = PipelineParams(parser)
    parser.add_argument('--ip', type=str, default="127.0.0.1")
    parser.add_argument('--port', type=int, default=6009)
    parser.add_argument('--detect_anomaly', action='store_true', default=False)
    parser.add_argument("--test_iterations", nargs="+", type=int, default=[7_000, 15_000])  ##default=[7_000, 30_000]
    parser.add_argument("--save_iterations", nargs="+", type=int, default=[7_000, 15_000])
    parser.add_argument("--quiet", action="store_true")
    parser.add_argument("--checkpoint_iterations", nargs="+", type=int, default=[])
    parser.add_argument("--start_checkpoint", type=str, default = None)
    parser.add_argument("--seed", type=int, default = 0)
    parser.add_argument("--logger_enabled", action="store_true")
    args = parser.parse_args(sys.argv[1:])
    args.save_iterations.append(args.iterations)
    
    print("Optimizing " + args.model_path)

    # Initialize system state (RNG)
    safe_state(args.quiet, args.seed)

    # Start GUI server, configure and run training
    network_gui.init(args.ip, args.port)
    torch.autograd.set_detect_anomaly(args.detect_anomaly)
    training(
        lp.extract(args),
        op.extract(args),
        pp.extract(args),
        args.test_iterations,
        args.save_iterations,
        args.checkpoint_iterations,
        args.start_checkpoint,
        args.logger_enabled)

    # All done
    print("\nTraining complete.")